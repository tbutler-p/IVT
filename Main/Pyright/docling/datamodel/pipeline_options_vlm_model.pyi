"""
This type stub file was generated by pyright.
"""

from enum import Enum
from typing import Any, Dict, List, Literal, Optional, Union
from docling_core.types.doc.page import SegmentedPage
from pydantic import AnyUrl, BaseModel
from transformers import StoppingCriteria
from typing_extensions import deprecated
from docling.datamodel.accelerator_options import AcceleratorDevice
from docling.models.utils.generation_utils import GenerationStopper

"""
This type stub file was generated by pyright.
"""
class BaseVlmOptions(BaseModel):
    kind: str
    prompt: str
    scale: float = ...
    max_size: Optional[int] = ...
    temperature: float = ...
    def build_prompt(self, page: Optional[SegmentedPage]) -> str:
        ...
    
    def decode_response(self, text: str) -> str:
        ...
    


class ResponseFormat(str, Enum):
    DOCTAGS = ...
    MARKDOWN = ...
    HTML = ...
    OTSL = ...
    PLAINTEXT = ...


class InferenceFramework(str, Enum):
    MLX = ...
    TRANSFORMERS = ...
    VLLM = ...


class TransformersModelType(str, Enum):
    AUTOMODEL = ...
    AUTOMODEL_VISION2SEQ = ...
    AUTOMODEL_CAUSALLM = ...
    AUTOMODEL_IMAGETEXTTOTEXT = ...


class TransformersPromptStyle(str, Enum):
    CHAT = ...
    RAW = ...
    NONE = ...


class InlineVlmOptions(BaseVlmOptions):
    model_config = ...
    kind: Literal["inline_model_options"] = ...
    repo_id: str
    revision: str = ...
    trust_remote_code: bool = ...
    load_in_8bit: bool = ...
    llm_int8_threshold: float = ...
    quantized: bool = ...
    inference_framework: InferenceFramework
    transformers_model_type: TransformersModelType = ...
    transformers_prompt_style: TransformersPromptStyle = ...
    response_format: ResponseFormat
    torch_dtype: Optional[str] = ...
    supported_devices: List[AcceleratorDevice] = ...
    stop_strings: List[str] = ...
    custom_stopping_criteria: List[Union[StoppingCriteria, GenerationStopper]] = ...
    extra_generation_config: Dict[str, Any] = ...
    extra_processor_kwargs: Dict[str, Any] = ...
    use_kv_cache: bool = ...
    max_new_tokens: int = ...
    track_generated_tokens: bool = ...
    @property
    def repo_cache_folder(self) -> str:
        ...
    


@deprecated("Use InlineVlmOptions instead.")
class HuggingFaceVlmOptions(InlineVlmOptions):
    ...


class ApiVlmOptions(BaseVlmOptions):
    model_config = ...
    kind: Literal["api_model_options"] = ...
    url: AnyUrl = ...
    headers: Dict[str, str] = ...
    params: Dict[str, Any] = ...
    timeout: float = ...
    concurrency: int = ...
    response_format: ResponseFormat
    stop_strings: List[str] = ...
    custom_stopping_criteria: List[Union[GenerationStopper]] = ...


