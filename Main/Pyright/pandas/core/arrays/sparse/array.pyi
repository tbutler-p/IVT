"""
This type stub file was generated by pyright.
"""

import numpy as np
from typing import Any, Literal, TYPE_CHECKING, overload
from pandas._libs.sparse import BlockIndex, IntIndex, SparseIndex
from pandas.util._decorators import doc
from pandas.core.dtypes.dtypes import SparseDtype
from pandas.core.arraylike import OpsMixin
from pandas.core.arrays import ExtensionArray
from pandas.core.base import PandasObject
from enum import Enum
from scipy.sparse import spmatrix
from pandas._typing import ArrayLike, AstypeArg, Axis, AxisInt, Dtype, FillnaOptions, NpDtype, NumpySorter, PositionalIndexer, Scalar, ScalarIndexer, Self, SequenceIndexer, npt
from pandas import Series

"""
SparseArray data structure
"""
if TYPE_CHECKING:
    class ellipsis(Enum):
        Ellipsis = ...
    
    
    Ellipsis = ...
    SparseIndexKind = Literal["integer", "block"]
else:
    ...
_sparray_doc_kwargs = ...
class SparseArray(OpsMixin, PandasObject, ExtensionArray):
    """
    An ExtensionArray for storing sparse data.

    Parameters
    ----------
    data : array-like or scalar
        A dense array of values to store in the SparseArray. This may contain
        `fill_value`.
    sparse_index : SparseIndex, optional
    fill_value : scalar, optional
        Elements in data that are ``fill_value`` are not stored in the
        SparseArray. For memory savings, this should be the most common value
        in `data`. By default, `fill_value` depends on the dtype of `data`:

        =========== ==========
        data.dtype  na_value
        =========== ==========
        float       ``np.nan``
        int         ``0``
        bool        False
        datetime64  ``pd.NaT``
        timedelta64 ``pd.NaT``
        =========== ==========

        The fill value is potentially specified in three ways. In order of
        precedence, these are

        1. The `fill_value` argument
        2. ``dtype.fill_value`` if `fill_value` is None and `dtype` is
           a ``SparseDtype``
        3. ``data.dtype.fill_value`` if `fill_value` is None and `dtype`
           is not a ``SparseDtype`` and `data` is a ``SparseArray``.

    kind : str
        Can be 'integer' or 'block', default is 'integer'.
        The type of storage for sparse locations.

        * 'block': Stores a `block` and `block_length` for each
          contiguous *span* of sparse values. This is best when
          sparse data tends to be clumped together, with large
          regions of ``fill-value`` values between sparse values.
        * 'integer': uses an integer to store the location of
          each sparse value.

    dtype : np.dtype or SparseDtype, optional
        The dtype to use for the SparseArray. For numpy dtypes, this
        determines the dtype of ``self.sp_values``. For SparseDtype,
        this determines ``self.sp_values`` and ``self.fill_value``.
    copy : bool, default False
        Whether to explicitly copy the incoming `data` array.

    Attributes
    ----------
    None

    Methods
    -------
    None

    Examples
    --------
    >>> from pandas.arrays import SparseArray
    >>> arr = SparseArray([0, 0, 1, 2])
    >>> arr
    [0, 0, 1, 2]
    Fill: 0
    IntIndex
    Indices: array([2, 3], dtype=int32)
    """
    _subtyp = ...
    _hidden_attrs = ...
    _sparse_index: SparseIndex
    _sparse_values: np.ndarray
    _dtype: SparseDtype
    def __init__(self, data, sparse_index=..., fill_value=..., kind: SparseIndexKind = ..., dtype: Dtype | None = ..., copy: bool = ...) -> None:
        ...
    
    @classmethod
    def from_spmatrix(cls, data: spmatrix) -> Self:
        """
        Create a SparseArray from a scipy.sparse matrix.

        Parameters
        ----------
        data : scipy.sparse.sp_matrix
            This should be a SciPy sparse matrix where the size
            of the second dimension is 1. In other words, a
            sparse matrix with a single column.

        Returns
        -------
        SparseArray

        Examples
        --------
        >>> import scipy.sparse
        >>> mat = scipy.sparse.coo_matrix((4, 1))
        >>> pd.arrays.SparseArray.from_spmatrix(mat)
        [0.0, 0.0, 0.0, 0.0]
        Fill: 0.0
        IntIndex
        Indices: array([], dtype=int32)
        """
        ...
    
    def __array__(self, dtype: NpDtype | None = ..., copy: bool | None = ...) -> np.ndarray:
        ...
    
    def __setitem__(self, key, value) -> None:
        ...
    
    @property
    def sp_index(self) -> SparseIndex:
        """
        The SparseIndex containing the location of non- ``fill_value`` points.
        """
        ...
    
    @property
    def sp_values(self) -> np.ndarray:
        """
        An ndarray containing the non- ``fill_value`` values.

        Examples
        --------
        >>> from pandas.arrays import SparseArray
        >>> s = SparseArray([0, 0, 1, 0, 2], fill_value=0)
        >>> s.sp_values
        array([1, 2])
        """
        ...
    
    @property
    def dtype(self) -> SparseDtype:
        ...
    
    @property
    def fill_value(self): # -> Any:
        """
        Elements in `data` that are `fill_value` are not stored.

        For memory savings, this should be the most common value in the array.

        Examples
        --------
        >>> ser = pd.Series([0, 0, 2, 2, 2], dtype="Sparse[int]")
        >>> ser.sparse.fill_value
        0
        >>> spa_dtype = pd.SparseDtype(dtype=np.int32, fill_value=2)
        >>> ser = pd.Series([0, 0, 2, 2, 2], dtype=spa_dtype)
        >>> ser.sparse.fill_value
        2
        """
        ...
    
    @fill_value.setter
    def fill_value(self, value) -> None:
        ...
    
    @property
    def kind(self) -> SparseIndexKind:
        """
        The kind of sparse index for this array. One of {'integer', 'block'}.
        """
        ...
    
    def __len__(self) -> int:
        ...
    
    @property
    def nbytes(self) -> int:
        ...
    
    @property
    def density(self) -> float:
        """
        The percent of non- ``fill_value`` points, as decimal.

        Examples
        --------
        >>> from pandas.arrays import SparseArray
        >>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)
        >>> s.density
        0.6
        """
        ...
    
    @property
    def npoints(self) -> int:
        """
        The number of non- ``fill_value`` points.

        Examples
        --------
        >>> from pandas.arrays import SparseArray
        >>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)
        >>> s.npoints
        3
        """
        ...
    
    def isna(self) -> Self:
        ...
    
    def fillna(self, value=..., method: FillnaOptions | None = ..., limit: int | None = ..., copy: bool = ...) -> Self:
        """
        Fill missing values with `value`.

        Parameters
        ----------
        value : scalar, optional
        method : str, optional

            .. warning::

               Using 'method' will result in high memory use,
               as all `fill_value` methods will be converted to
               an in-memory ndarray

        limit : int, optional

        copy: bool, default True
            Ignored for SparseArray.

        Returns
        -------
        SparseArray

        Notes
        -----
        When `value` is specified, the result's ``fill_value`` depends on
        ``self.fill_value``. The goal is to maintain low-memory use.

        If ``self.fill_value`` is NA, the result dtype will be
        ``SparseDtype(self.dtype, fill_value=value)``. This will preserve
        amount of memory used before and after filling.

        When ``self.fill_value`` is not NA, the result dtype will be
        ``self.dtype``. Again, this preserves the amount of memory used.
        """
        ...
    
    def shift(self, periods: int = ..., fill_value=...) -> Self:
        ...
    
    @doc(ExtensionArray.duplicated)
    def duplicated(self, keep: Literal["first", "last", False] = ...) -> npt.NDArray[np.bool_]:
        ...
    
    def unique(self) -> Self:
        ...
    
    def factorize(self, use_na_sentinel: bool = ...) -> tuple[np.ndarray, SparseArray]:
        ...
    
    def value_counts(self, dropna: bool = ...) -> Series:
        """
        Returns a Series containing counts of unique values.

        Parameters
        ----------
        dropna : bool, default True
            Don't include counts of NaN, even if NaN is in sp_values.

        Returns
        -------
        counts : Series
        """
        ...
    
    @overload
    def __getitem__(self, key: ScalarIndexer) -> Any:
        ...
    
    @overload
    def __getitem__(self, key: SequenceIndexer | tuple[int | ellipsis, ...]) -> Self:
        ...
    
    def __getitem__(self, key: PositionalIndexer | tuple[int | ellipsis, ...]) -> Self | Any:
        ...
    
    def take(self, indices, *, allow_fill: bool = ..., fill_value=...) -> Self:
        ...
    
    def searchsorted(self, v: ArrayLike | object, side: Literal["left", "right"] = ..., sorter: NumpySorter | None = ...) -> npt.NDArray[np.intp] | np.intp:
        ...
    
    def copy(self) -> Self:
        ...
    
    def astype(self, dtype: AstypeArg | None = ..., copy: bool = ...): # -> Self | ExtensionArray | ndarray[Any, Any]:
        """
        Change the dtype of a SparseArray.

        The output will always be a SparseArray. To convert to a dense
        ndarray with a certain dtype, use :meth:`numpy.asarray`.

        Parameters
        ----------
        dtype : np.dtype or ExtensionDtype
            For SparseDtype, this changes the dtype of
            ``self.sp_values`` and the ``self.fill_value``.

            For other dtypes, this only changes the dtype of
            ``self.sp_values``.

        copy : bool, default True
            Whether to ensure a copy is made, even if not necessary.

        Returns
        -------
        SparseArray

        Examples
        --------
        >>> arr = pd.arrays.SparseArray([0, 0, 1, 2])
        >>> arr
        [0, 0, 1, 2]
        Fill: 0
        IntIndex
        Indices: array([2, 3], dtype=int32)

        >>> arr.astype(SparseDtype(np.dtype('int32')))
        [0, 0, 1, 2]
        Fill: 0
        IntIndex
        Indices: array([2, 3], dtype=int32)

        Using a NumPy dtype with a different kind (e.g. float) will coerce
        just ``self.sp_values``.

        >>> arr.astype(SparseDtype(np.dtype('float64')))
        ... # doctest: +NORMALIZE_WHITESPACE
        [nan, nan, 1.0, 2.0]
        Fill: nan
        IntIndex
        Indices: array([2, 3], dtype=int32)

        Using a SparseDtype, you can also change the fill value as well.

        >>> arr.astype(SparseDtype("float64", fill_value=0.0))
        ... # doctest: +NORMALIZE_WHITESPACE
        [0.0, 0.0, 1.0, 2.0]
        Fill: 0.0
        IntIndex
        Indices: array([2, 3], dtype=int32)
        """
        ...
    
    def map(self, mapper, na_action=...) -> Self:
        """
        Map categories using an input mapping or function.

        Parameters
        ----------
        mapper : dict, Series, callable
            The correspondence from old values to new.
        na_action : {None, 'ignore'}, default None
            If 'ignore', propagate NA values, without passing them to the
            mapping correspondence.

        Returns
        -------
        SparseArray
            The output array will have the same density as the input.
            The output fill value will be the result of applying the
            mapping to ``self.fill_value``

        Examples
        --------
        >>> arr = pd.arrays.SparseArray([0, 1, 2])
        >>> arr.map(lambda x: x + 10)
        [10, 11, 12]
        Fill: 10
        IntIndex
        Indices: array([1, 2], dtype=int32)

        >>> arr.map({0: 10, 1: 11, 2: 12})
        [10, 11, 12]
        Fill: 10
        IntIndex
        Indices: array([1, 2], dtype=int32)

        >>> arr.map(pd.Series([10, 11, 12], index=[0, 1, 2]))
        [10, 11, 12]
        Fill: 10
        IntIndex
        Indices: array([1, 2], dtype=int32)
        """
        ...
    
    def to_dense(self) -> np.ndarray:
        """
        Convert SparseArray to a NumPy array.

        Returns
        -------
        arr : NumPy array
        """
        ...
    
    def __setstate__(self, state) -> None:
        """Necessary for making this object picklable"""
        ...
    
    def nonzero(self) -> tuple[npt.NDArray[np.int32]]:
        ...
    
    def all(self, axis=..., *args, **kwargs): # -> numpy.bool[builtins.bool] | Literal[False]:
        """
        Tests whether all elements evaluate True

        Returns
        -------
        all : bool

        See Also
        --------
        numpy.all
        """
        ...
    
    def any(self, axis: AxisInt = ..., *args, **kwargs) -> bool:
        """
        Tests whether at least one of elements evaluate True

        Returns
        -------
        any : bool

        See Also
        --------
        numpy.any
        """
        ...
    
    def sum(self, axis: AxisInt = ..., min_count: int = ..., skipna: bool = ..., *args, **kwargs) -> Scalar:
        """
        Sum of non-NA/null values

        Parameters
        ----------
        axis : int, default 0
            Not Used. NumPy compatibility.
        min_count : int, default 0
            The required number of valid values to perform the summation. If fewer
            than ``min_count`` valid values are present, the result will be the missing
            value indicator for subarray type.
        *args, **kwargs
            Not Used. NumPy compatibility.

        Returns
        -------
        scalar
        """
        ...
    
    def cumsum(self, axis: AxisInt = ..., *args, **kwargs) -> SparseArray:
        """
        Cumulative sum of non-NA/null values.

        When performing the cumulative summation, any non-NA/null values will
        be skipped. The resulting SparseArray will preserve the locations of
        NaN values, but the fill value will be `np.nan` regardless.

        Parameters
        ----------
        axis : int or None
            Axis over which to perform the cumulative summation. If None,
            perform cumulative summation over flattened array.

        Returns
        -------
        cumsum : SparseArray
        """
        ...
    
    def mean(self, axis: Axis = ..., *args, **kwargs): # -> Any:
        """
        Mean of non-NA/null values

        Returns
        -------
        mean : float
        """
        ...
    
    def max(self, *, axis: AxisInt | None = ..., skipna: bool = ...): # -> Scalar:
        """
        Max of array values, ignoring NA values if specified.

        Parameters
        ----------
        axis : int, default 0
            Not Used. NumPy compatibility.
        skipna : bool, default True
            Whether to ignore NA values.

        Returns
        -------
        scalar
        """
        ...
    
    def min(self, *, axis: AxisInt | None = ..., skipna: bool = ...): # -> Scalar:
        """
        Min of array values, ignoring NA values if specified.

        Parameters
        ----------
        axis : int, default 0
            Not Used. NumPy compatibility.
        skipna : bool, default True
            Whether to ignore NA values.

        Returns
        -------
        scalar
        """
        ...
    
    def argmax(self, skipna: bool = ...) -> int:
        ...
    
    def argmin(self, skipna: bool = ...) -> int:
        ...
    
    _HANDLED_TYPES = ...
    def __array_ufunc__(self, ufunc: np.ufunc, method: str, *inputs, **kwargs): # -> _NotImplementedType | tuple[Any, ...] | Any | tuple[Self, ...] | Self | None:
        ...
    
    _logical_method = ...
    def __pos__(self) -> SparseArray:
        ...
    
    def __neg__(self) -> SparseArray:
        ...
    
    def __invert__(self) -> SparseArray:
        ...
    
    def __abs__(self) -> SparseArray:
        ...
    
    def __repr__(self) -> str:
        ...
    


@overload
def make_sparse_index(length: int, indices, kind: Literal["block"]) -> BlockIndex:
    ...

@overload
def make_sparse_index(length: int, indices, kind: Literal["integer"]) -> IntIndex:
    ...

def make_sparse_index(length: int, indices, kind: SparseIndexKind) -> SparseIndex:
    ...

