"""
This type stub file was generated by pyright.
"""

import torch
import torch.nn as nn
from collections import OrderedDict
from dataclasses import dataclass
from typing import Optional, Tuple, Union

"""
This code is refer from:
https://github.com/huggingface/transformers/blob/main/src/transformers/models/donut/modeling_donut_swin.py

"""
_CONFIG_FOR_DOC = ...
_CHECKPOINT_FOR_DOC = ...
_EXPECTED_OUTPUT_SHAPE = ...
class DonutSwinConfig:
    model_type = ...
    attribute_map = ...
    def __init__(self, image_size=..., patch_size=..., num_channels=..., embed_dim=..., depths=..., num_heads=..., window_size=..., mlp_ratio=..., qkv_bias=..., hidden_dropout_prob=..., attention_probs_dropout_prob=..., drop_path_rate=..., hidden_act=..., use_absolute_embeddings=..., initializer_range=..., layer_norm_eps=..., **kwargs) -> None:
        ...
    


@dataclass
class DonutSwinEncoderOutput(OrderedDict):
    last_hidden_state = ...
    hidden_states = ...
    attentions = ...
    reshaped_hidden_states = ...
    def __init__(self, *args, **kwargs) -> None:
        ...
    
    def __getitem__(self, k):
        ...
    
    def __setattr__(self, name, value): # -> None:
        ...
    
    def __setitem__(self, key, value): # -> None:
        ...
    
    def to_tuple(self): # -> tuple[Any, ...]:
        """
        Convert self to a tuple containing all the attributes/keys that are not `None`.
        """
        ...
    


@dataclass
class DonutSwinModelOutput(OrderedDict):
    last_hidden_state = ...
    pooler_output = ...
    hidden_states = ...
    attentions = ...
    reshaped_hidden_states = ...
    def __init__(self, *args, **kwargs) -> None:
        ...
    
    def __getitem__(self, k):
        ...
    
    def __setattr__(self, name, value): # -> None:
        ...
    
    def __setitem__(self, key, value): # -> None:
        ...
    
    def to_tuple(self): # -> tuple[Any, ...]:
        """
        Convert self to a tuple containing all the attributes/keys that are not `None`.
        """
        ...
    


def window_partition(input_feature, window_size):
    """
    Partitions the given input into windows.
    """
    ...

def window_reverse(windows, window_size, height, width):
    """
    Merges windows to produce higher resolution features.
    """
    ...

class DonutSwinEmbeddings(nn.Module):
    """
    Construct the patch and position embeddings. Optionally, also the mask token.
    """
    def __init__(self, config, use_mask_token=...) -> None:
        ...
    
    def forward(self, pixel_values, bool_masked_pos=...): # -> tuple[Any, Any]:
        ...
    


class MyConv2d(nn.Conv2d):
    def __init__(self, in_channel, out_channels, kernel_size, stride=..., padding=..., dilation=..., groups=..., bias_attr=..., eps=...) -> None:
        ...
    
    def forward(self, x):
        ...
    


class DonutSwinPatchEmbeddings(nn.Module):
    """
    This class turns `pixel_values` of shape `(batch_size, num_channels, height, width)` into the initial
    `hidden_states` (patch embeddings) of shape `(batch_size, seq_length, hidden_size)` to be consumed by a
    Transformer.
    """
    def __init__(self, config) -> None:
        ...
    
    def maybe_pad(self, pixel_values, height, width): # -> Tensor:
        ...
    
    def forward(self, pixel_values) -> Tuple[torch.Tensor, Tuple[int]]:
        ...
    


class DonutSwinPatchMerging(nn.Module):
    """
    Patch Merging Layer.

    Args:
        input_resolution (`Tuple[int]`):
            Resolution of input feature.
        dim (`int`):
            Number of input channels.
        norm_layer (`nn.Module`, *optional*, defaults to `nn.LayerNorm`):
            Normalization layer class.
    """
    def __init__(self, input_resolution: Tuple[int], dim: int, norm_layer: nn.Module = ..., is_export=...) -> None:
        ...
    
    def maybe_pad(self, input_feature, height, width): # -> Tensor:
        ...
    
    def forward(self, input_feature: torch.Tensor, input_dimensions: Tuple[int, int]) -> torch.Tensor:
        ...
    


def drop_path(input: torch.Tensor, drop_prob: float = ..., training: bool = ...) -> torch.Tensor:
    ...

class DonutSwinDropPath(nn.Module):
    """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks)."""
    def __init__(self, drop_prob: Optional[float] = ...) -> None:
        ...
    
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:
        ...
    
    def extra_repr(self) -> str:
        ...
    


class DonutSwinSelfAttention(nn.Module):
    def __init__(self, config, dim, num_heads, window_size) -> None:
        ...
    
    def transpose_for_scores(self, x):
        ...
    
    def forward(self, hidden_states: torch.Tensor, attention_mask=..., head_mask=..., output_attentions=...) -> Tuple[torch.Tensor]:
        ...
    


class DonutSwinSelfOutput(nn.Module):
    def __init__(self, config, dim) -> None:
        ...
    
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:
        ...
    


class DonutSwinAttention(nn.Module):
    def __init__(self, config, dim, num_heads, window_size) -> None:
        ...
    
    def forward(self, hidden_states: torch.Tensor, attention_mask=..., head_mask=..., output_attentions=...) -> Tuple[torch.Tensor]:
        ...
    


class DonutSwinIntermediate(nn.Module):
    def __init__(self, config, dim) -> None:
        ...
    
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:
        ...
    


class DonutSwinOutput(nn.Module):
    def __init__(self, config, dim) -> None:
        ...
    
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:
        ...
    


class DonutSwinLayer(nn.Module):
    def __init__(self, config, dim, input_resolution, num_heads, shift_size=...) -> None:
        ...
    
    def set_shift_and_window_size(self, input_resolution): # -> None:
        ...
    
    def get_attn_mask_export(self, height, width, dtype): # -> None:
        ...
    
    def get_attn_mask(self, height, width, dtype): # -> None:
        ...
    
    def maybe_pad(self, hidden_states, height, width): # -> tuple[Tensor, tuple[Literal[0], Literal[0], Literal[0], Any, Literal[0], Any, Literal[0], Literal[0]]]:
        ...
    
    def forward(self, hidden_states: torch.Tensor, input_dimensions: Tuple[int, int], head_mask=..., output_attentions=..., always_partition=...) -> Tuple[torch.Tensor, torch.Tensor]:
        ...
    


class DonutSwinStage(nn.Module):
    def __init__(self, config, dim, input_resolution, depth, num_heads, drop_path, downsample) -> None:
        ...
    
    def forward(self, hidden_states: torch.Tensor, input_dimensions: Tuple[int, int], head_mask=..., output_attentions=..., always_partition=...) -> Tuple[torch.Tensor]:
        ...
    


class DonutSwinEncoder(nn.Module):
    def __init__(self, config, grid_size) -> None:
        ...
    
    def forward(self, hidden_states: torch.Tensor, input_dimensions: Tuple[int, int], head_mask=..., output_attentions=..., output_hidden_states=..., output_hidden_states_before_downsampling=..., always_partition=..., return_dict=...): # -> tuple[Any, ...] | DonutSwinEncoderOutput:
        ...
    


class DonutSwinPreTrainedModel(nn.Module):
    """
    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained
    models.
    """
    config_class = DonutSwinConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...
    def post_init(self): # -> None:
        ...
    
    def get_head_mask(self, head_mask, num_hidden_layers, is_attention_chunked=...): # -> Any:
        ...
    


class DonutSwinModel(DonutSwinPreTrainedModel):
    def __init__(self, in_channels=..., hidden_size=..., num_layers=..., num_heads=..., add_pooling_layer=..., use_mask_token=..., is_export=...) -> None:
        ...
    
    def get_input_embeddings(self): # -> DonutSwinPatchEmbeddings:
        ...
    
    def forward(self, input_data=..., bool_masked_pos=..., head_mask=..., output_attentions=..., output_hidden_states=..., return_dict=...) -> Union[Tuple, DonutSwinModelOutput]:
        r"""
        bool_masked_pos (`paddle.BoolTensor` of shape `(batch_size, num_patches)`):
            Boolean masked positions. Indicates which patches are masked (1) and which aren't (0).
        """
        ...
    


