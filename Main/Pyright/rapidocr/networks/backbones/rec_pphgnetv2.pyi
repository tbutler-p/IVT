"""
This type stub file was generated by pyright.
"""

import torch
import torch.nn as nn
from typing import Callable, Dict, List, Union

"""
This code is refer from:
https://github.com/PaddlePaddle/PaddleClas/blob/2f36cab604e439b59d1a854df34ece3b10d888e3/ppcls/arch/backbone/legendary_models/pp_hgnet_v2.py
"""
class IdentityBasedConv1x1(nn.Conv2d):
    def __init__(self, channels, groups=...) -> None:
        ...
    
    def forward(self, input):
        ...
    
    def get_actual_kernel(self): # -> Tensor:
        ...
    


class BNAndPad(nn.Module):
    def __init__(self, pad_pixels, num_features, epsilon=..., momentum=..., last_conv_bias=..., bn=...) -> None:
        ...
    
    def forward(self, input): # -> Tensor | Any:
        ...
    
    @property
    def weight(self): # -> Parameter:
        ...
    
    @property
    def bias(self): # -> Parameter:
        ...
    


def conv_bn(in_channels, out_channels, kernel_size, stride=..., padding=..., dilation=..., groups=..., padding_mode=...): # -> Sequential:
    ...

def transI_fusebn(kernel, bn): # -> tuple[Any, Any]:
    ...

def transII_addbranch(kernels, biases): # -> tuple[int, int]:
    ...

def transIII_1x1_kxk(k1, b1, k2, b2, groups): # -> tuple[Tensor, Any]:
    ...

def transIV_depthconcat(kernels, biases): # -> tuple[Tensor, Tensor]:
    ...

def transV_avg(channels, kernel_size, groups): # -> Tensor:
    ...

def transVI_multiscale(kernel, target_kernel_size): # -> Tensor:
    ...

class DiverseBranchBlock(nn.Module):
    def __init__(self, num_channels, num_filters, filter_size, stride=..., groups=..., act=..., is_repped=..., single_init=..., **kwargs) -> None:
        ...
    
    def forward(self, inputs): # -> Any:
        ...
    
    def init_gamma(self, gamma_value): # -> None:
        ...
    
    def single_init(self): # -> None:
        ...
    
    def get_equivalent_kernel_bias(self): # -> tuple[int, int]:
        ...
    
    def re_parameterize(self): # -> None:
        ...
    


class Identity(nn.Module):
    def __init__(self) -> None:
        ...
    
    def forward(self, inputs):
        ...
    


class TheseusLayer(nn.Module):
    def __init__(self, *args, **kwargs) -> None:
        ...
    
    def init_net(self, stages_pattern=..., return_patterns=..., return_stages=..., freeze_befor=..., stop_after=..., *args, **kwargs): # -> None:
        ...
    
    def init_res(self, stages_pattern, return_patterns=..., return_stages=...): # -> None:
        ...
    
    def replace_sub(self, *args, **kwargs) -> None:
        ...
    
    def upgrade_sublayer(self, layer_name_pattern: Union[str, List[str]], handle_func: Callable[[nn.Module, str], nn.Module]) -> Dict[str, nn.Module]:
        """use 'handle_func' to modify the sub-layer(s) specified by 'layer_name_pattern'.

        Args:
            layer_name_pattern (Union[str, List[str]]): The name of layer to be modified by 'handle_func'.
            handle_func (Callable[[nn.Module, str], nn.Module]): The function to modify target layer specified by 'layer_name_pattern'. The formal params are the layer(nn.Module) and pattern(str) that is (a member of) layer_name_pattern (when layer_name_pattern is List type). And the return is the layer processed.

        Returns:
            Dict[str, nn.Module]: The key is the pattern and corresponding value is the result returned by 'handle_func()'.

        Examples:

            from paddle import nn
            import paddleclas

            def rep_func(layer: nn.Module, pattern: str):
                new_layer = nn.Conv2d(
                    in_channels=layer._in_channels,
                    out_channels=layer._out_channels,
                    kernel_size=5,
                    padding=2
                )
                return new_layer

            net = paddleclas.MobileNetV1()
            res = net.upgrade_sublayer(layer_name_pattern=["blocks[11].depthwise_conv.conv", "blocks[12].depthwise_conv.conv"], handle_func=rep_func)
            print(res)
            # {'blocks[11].depthwise_conv.conv': the corresponding new_layer, 'blocks[12].depthwise_conv.conv': the corresponding new_layer}
        """
        ...
    
    def stop_after(self, stop_layer_name: str) -> bool:
        """stop forward and backward after 'stop_layer_name'.

        Args:
            stop_layer_name (str): The name of layer that stop forward and backward after this layer.

        Returns:
            bool: 'True' if successful, 'False' otherwise.
        """
        ...
    
    def freeze_befor(self, layer_name: str) -> bool:
        """freeze the layer named layer_name and its previous layer.

        Args:
            layer_name (str): The name of layer that would be freezed.

        Returns:
            bool: 'True' if successful, 'False' otherwise.
        """
        ...
    
    def update_res(self, return_patterns: Union[str, List[str]]) -> Dict[str, nn.Module]:
        """update the result(s) to be returned.

        Args:
            return_patterns (Union[str, List[str]]): The name of layer to return output.

        Returns:
            Dict[str, nn.Module]: The pattern(str) and corresponding layer(nn.Module) that have been set successfully.
        """
        class Handler:
            ...
        
        
    


def save_sub_res_hook(layer, input, output): # -> None:
    ...

def set_identity(parent_layer: nn.Module, layer_name: str, layer_index_list: str = ...) -> bool:
    """set the layer specified by layer_name and layer_index_list to Identity.

    Args:
        parent_layer (nn.Module): The parent layer of target layer specified by layer_name and layer_index_list.
        layer_name (str): The name of target layer to be set to Identity.
        layer_index_list (str, optional): The index of target layer to be set to Identity in parent_layer. Defaults to None.

    Returns:
        bool: True if successfully, False otherwise.
    """
    ...

def parse_pattern_str(pattern: str, parent_layer: nn.Module) -> Union[None, List[Dict[str, Union[nn.Module, str, None]]]]:
    """parse the string type pattern.

    Args:
        pattern (str): The pattern to describe layer.
        parent_layer (nn.Module): The root layer relative to the pattern.

    Returns:
        Union[None, List[Dict[str, Union[nn.Module, str, None]]]]: None if failed. If successfully, the members are layers parsed in order:
                                                                [
                                                                    {"layer": first layer, "name": first layer's name parsed, "index": first layer's index parsed if exist},
                                                                    {"layer": second layer, "name": second layer's name parsed, "index": second layer's index parsed if exist},
                                                                    ...
                                                                ]
    """
    ...

MODEL_URLS = ...
__all__ = list(MODEL_URLS.keys())
class LearnableAffineBlock(TheseusLayer):
    """
    Create a learnable affine block module. This module can significantly improve accuracy on smaller models.

    Args:
        scale_value (float): The initial value of the scale parameter, default is 1.0.
        bias_value (float): The initial value of the bias parameter, default is 0.0.
        lr_mult (float): The learning rate multiplier, default is 1.0.
        lab_lr (float): The learning rate, default is 0.01.
    """
    def __init__(self, scale_value=..., bias_value=..., lr_mult=..., lab_lr=...) -> None:
        ...
    
    def forward(self, x):
        ...
    


class ConvBNAct(TheseusLayer):
    """
    ConvBNAct is a combination of convolution and batchnorm layers.

    Args:
        in_channels (int): Number of input channels.
        out_channels (int): Number of output channels.
        kernel_size (int): Size of the convolution kernel. Defaults to 3.
        stride (int): Stride of the convolution. Defaults to 1.
        padding (int/str): Padding or padding type for the convolution. Defaults to 1.
        groups (int): Number of groups for the convolution. Defaults to 1.
        use_act: (bool): Whether to use activation function. Defaults to True.
        use_lab (bool): Whether to use the LAB operation. Defaults to False.
        lr_mult (float): Learning rate multiplier for the layer. Defaults to 1.0.
    """
    def __init__(self, in_channels, out_channels, kernel_size=..., stride=..., padding=..., groups=..., use_act=..., use_lab=..., lr_mult=...) -> None:
        ...
    
    def forward(self, x): # -> Any:
        ...
    


class LightConvBNAct(TheseusLayer):
    """
    LightConvBNAct is a combination of pw and dw layers.

    Args:
        in_channels (int): Number of input channels.
        out_channels (int): Number of output channels.
        kernel_size (int): Size of the depth-wise convolution kernel.
        use_lab (bool): Whether to use the LAB operation. Defaults to False.
        lr_mult (float): Learning rate multiplier for the layer. Defaults to 1.0.
    """
    def __init__(self, in_channels, out_channels, kernel_size, use_lab=..., lr_mult=..., **kwargs) -> None:
        ...
    
    def forward(self, x): # -> Any:
        ...
    


class PaddingSameAsPaddleMaxPool2d(torch.nn.Module):
    def __init__(self, kernel_size, stride=...) -> None:
        ...
    
    def forward(self, x): # -> Any:
        ...
    


class StemBlock(TheseusLayer):
    """
    StemBlock for PP-HGNetV2.

    Args:
        in_channels (int): Number of input channels.
        mid_channels (int): Number of middle channels.
        out_channels (int): Number of output channels.
        use_lab (bool): Whether to use the LAB operation. Defaults to False.
        lr_mult (float): Learning rate multiplier for the layer. Defaults to 1.0.
    """
    def __init__(self, in_channels, mid_channels, out_channels, use_lab=..., lr_mult=..., text_rec=...) -> None:
        ...
    
    def forward(self, x): # -> Any:
        ...
    


class HGV2_Block(TheseusLayer):
    """
    HGV2_Block, the basic unit that constitutes the HGV2_Stage.

    Args:
        in_channels (int): Number of input channels.
        mid_channels (int): Number of middle channels.
        out_channels (int): Number of output channels.
        kernel_size (int): Size of the convolution kernel. Defaults to 3.
        layer_num (int): Number of layers in the HGV2 block. Defaults to 6.
        stride (int): Stride of the convolution. Defaults to 1.
        padding (int/str): Padding or padding type for the convolution. Defaults to 1.
        groups (int): Number of groups for the convolution. Defaults to 1.
        use_act (bool): Whether to use activation function. Defaults to True.
        use_lab (bool): Whether to use the LAB operation. Defaults to False.
        lr_mult (float): Learning rate multiplier for the layer. Defaults to 1.0.
    """
    def __init__(self, in_channels, mid_channels, out_channels, kernel_size=..., layer_num=..., identity=..., light_block=..., use_lab=..., lr_mult=...) -> None:
        ...
    
    def forward(self, x): # -> Any:
        ...
    


class HGV2_Stage(TheseusLayer):
    """
    HGV2_Stage, the basic unit that constitutes the PPHGNetV2.

    Args:
        in_channels (int): Number of input channels.
        mid_channels (int): Number of middle channels.
        out_channels (int): Number of output channels.
        block_num (int): Number of blocks in the HGV2 stage.
        layer_num (int): Number of layers in the HGV2 block. Defaults to 6.
        is_downsample (bool): Whether to use downsampling operation. Defaults to False.
        light_block (bool): Whether to use light block. Defaults to True.
        kernel_size (int): Size of the convolution kernel. Defaults to 3.
        use_lab (bool, optional): Whether to use the LAB operation. Defaults to False.
        lr_mult (float, optional): Learning rate multiplier for the layer. Defaults to 1.0.
    """
    def __init__(self, in_channels, mid_channels, out_channels, block_num, layer_num=..., is_downsample=..., light_block=..., kernel_size=..., use_lab=..., stride=..., lr_mult=...) -> None:
        ...
    
    def forward(self, x): # -> Any:
        ...
    


class PPHGNetV2(TheseusLayer):
    """
    PPHGNetV2

    Args:
        stage_config (dict): Config for PPHGNetV2 stages. such as the number of channels, stride, etc.
        stem_channels: (list): Number of channels of the stem of the PPHGNetV2.
        use_lab (bool): Whether to use the LAB operation. Defaults to False.
        use_last_conv (bool): Whether to use the last conv layer as the output channel. Defaults to True.
        class_expand (int): Number of channels for the last 1x1 convolutional layer.
        drop_prob (float): Dropout probability for the last 1x1 convolutional layer. Defaults to 0.0.
        class_num (int): The number of classes for the classification layer. Defaults to 1000.
        lr_mult_list (list): Learning rate multiplier for the stages. Defaults to [1.0, 1.0, 1.0, 1.0, 1.0].
    Returns:
        model: nn.Module. Specific PPHGNetV2 model depends on args.
    """
    def __init__(self, stage_config, stem_channels=..., use_lab=..., use_last_conv=..., class_expand=..., dropout_prob=..., class_num=..., lr_mult_list=..., det=..., text_rec=..., out_indices=..., **kwargs) -> None:
        ...
    
    def forward(self, x): # -> list[Any] | Tensor | Any:
        ...
    


def PPHGNetV2_B0(pretrained=..., use_ssld=..., **kwargs): # -> PPHGNetV2:
    """
    PPHGNetV2_B0
    Args:
        pretrained (bool/str): If `True` load pretrained parameters, `False` otherwise.
                    If str, means the path of the pretrained model.
        use_ssld (bool) Whether using ssld pretrained model when pretrained is True.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B0` model depends on args.
    """
    ...

def PPHGNetV2_B1(pretrained=..., use_ssld=..., **kwargs): # -> PPHGNetV2:
    """
    PPHGNetV2_B1
    Args:
        pretrained (bool/str): If `True` load pretrained parameters, `False` otherwise.
                    If str, means the path of the pretrained model.
        use_ssld (bool) Whether using ssld pretrained model when pretrained is True.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B1` model depends on args.
    """
    ...

def PPHGNetV2_B2(pretrained=..., use_ssld=..., **kwargs): # -> PPHGNetV2:
    """
    PPHGNetV2_B2
    Args:
        pretrained (bool/str): If `True` load pretrained parameters, `False` otherwise.
                    If str, means the path of the pretrained model.
        use_ssld (bool) Whether using ssld pretrained model when pretrained is True.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B2` model depends on args.
    """
    ...

def PPHGNetV2_B3(pretrained=..., use_ssld=..., **kwargs): # -> PPHGNetV2:
    """
    PPHGNetV2_B3
    Args:
        pretrained (bool/str): If `True` load pretrained parameters, `False` otherwise.
                    If str, means the path of the pretrained model.
        use_ssld (bool) Whether using ssld pretrained model when pretrained is True.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B3` model depends on args.
    """
    ...

def PPHGNetV2_B4(pretrained=..., use_ssld=..., det=..., text_rec=..., **kwargs): # -> PPHGNetV2:
    """
    PPHGNetV2_B4
    Args:
        pretrained (bool/str): If `True` load pretrained parameters, `False` otherwise.
                    If str, means the path of the pretrained model.
        use_ssld (bool) Whether using ssld pretrained model when pretrained is True.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B4` model depends on args.
    """
    ...

def PPHGNetV2_B5(pretrained=..., use_ssld=..., **kwargs): # -> PPHGNetV2:
    """
    PPHGNetV2_B5
    Args:
        pretrained (bool/str): If `True` load pretrained parameters, `False` otherwise.
                    If str, means the path of the pretrained model.
        use_ssld (bool) Whether using ssld pretrained model when pretrained is True.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B5` model depends on args.
    """
    ...

def PPHGNetV2_B6(pretrained=..., use_ssld=..., **kwargs): # -> PPHGNetV2:
    """
    PPHGNetV2_B6
    Args:
        pretrained (bool/str): If `True` load pretrained parameters, `False` otherwise.
                    If str, means the path of the pretrained model.
        use_ssld (bool) Whether using ssld pretrained model when pretrained is True.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B6` model depends on args.
    """
    ...

class PPHGNetV2_B4_Formula(nn.Module):
    """
    PPHGNetV2_B4_Formula
    Args:
        in_channels (int): Number of input channels. Default is 3 (for RGB images).
        class_num (int): Number of classes for classification. Default is 1000.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B4` model with defined architecture.
    """
    def __init__(self, in_channels=..., class_num=...) -> None:
        ...
    
    def forward(self, input_data): # -> tuple[DonutSwinModelOutput, Any, Any] | DonutSwinModelOutput:
        ...
    


class PPHGNetV2_B6_Formula(nn.Module):
    """
    PPHGNetV2_B6_Formula
    Args:
        in_channels (int): Number of input channels. Default is 3 (for RGB images).
        class_num (int): Number of classes for classification. Default is 1000.
    Returns:
        model: nn.Module. Specific `PPHGNetV2_B6` model with defined architecture.
    """
    def __init__(self, in_channels=..., class_num=...) -> None:
        ...
    
    def forward(self, input_data): # -> tuple[DonutSwinModelOutput, Any, Any] | DonutSwinModelOutput:
        ...
    


