"""
This type stub file was generated by pyright.
"""

import asyncio
from typing import AsyncGenerator, Iterable, Optional, Union
from huggingface_hub import ChatCompletionInputMessage, ChatCompletionStreamOutput, MCPClient
from .._providers import PROVIDER_OR_POLICY_T
from .types import ServerConfig

class Agent(MCPClient):
    """
    Implementation of a Simple Agent, which is a simple while loop built right on top of an [`MCPClient`].

    > [!WARNING]
    > This class is experimental and might be subject to breaking changes in the future without prior notice.

    Args:
        model (`str`, *optional*):
            The model to run inference with. Can be a model id hosted on the Hugging Face Hub, e.g. `meta-llama/Meta-Llama-3-8B-Instruct`
            or a URL to a deployed Inference Endpoint or other local or remote endpoint.
        servers (`Iterable[Dict]`):
            MCP servers to connect to. Each server is a dictionary containing a `type` key and a `config` key. The `type` key can be `"stdio"` or `"sse"`, and the `config` key is a dictionary of arguments for the server.
        provider (`str`, *optional*):
            Name of the provider to use for inference. Defaults to "auto" i.e. the first of the providers available for the model, sorted by the user's order in https://hf.co/settings/inference-providers.
            If model is a URL or `base_url` is passed, then `provider` is not used.
        base_url (`str`, *optional*):
            The base URL to run inference. Defaults to None.
        api_key (`str`, *optional*):
            Token to use for authentication. Will default to the locally Hugging Face saved token if not provided. You can also use your own provider API key to interact directly with the provider's service.
        prompt (`str`, *optional*):
            The system prompt to use for the agent. Defaults to the default system prompt in `constants.py`.
    """
    def __init__(self, *, model: Optional[str] = ..., servers: Iterable[ServerConfig], provider: Optional[PROVIDER_OR_POLICY_T] = ..., base_url: Optional[str] = ..., api_key: Optional[str] = ..., prompt: Optional[str] = ...) -> None:
        ...
    
    async def load_tools(self) -> None:
        ...
    
    async def run(self, user_input: str, *, abort_event: Optional[asyncio.Event] = ...) -> AsyncGenerator[Union[ChatCompletionStreamOutput, ChatCompletionInputMessage], None]:
        """
        Run the agent with the given user input.

        Args:
            user_input (`str`):
                The user input to run the agent with.
            abort_event (`asyncio.Event`, *optional*):
                An event that can be used to abort the agent. If the event is set, the agent will stop running.
        """
        ...
    


