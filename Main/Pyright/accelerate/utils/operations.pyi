"""
This type stub file was generated by pyright.
"""

import torch
from contextlib import contextmanager
from typing import Any
from .imports import is_torch_distributed_available, is_torch_xla_available

"""
A set of basic tensor ops compatible with tpu, gpu, and multigpu
"""
if is_torch_xla_available():
    ...
if is_torch_distributed_available():
    ...
def is_torch_tensor(tensor): # -> bool:
    ...

def is_torch_xpu_tensor(tensor):
    ...

def is_tensor_information(tensor_info): # -> bool:
    ...

def is_namedtuple(data): # -> bool:
    """
    Checks if `data` is a `namedtuple` or not. Can have false positives, but only if a user is trying to mimic a
    `namedtuple` perfectly.
    """
    ...

def honor_type(obj, generator): # -> Any:
    """
    Cast a generator to the same type as obj (list, tuple, or namedtuple)
    """
    ...

def recursively_apply(func, data, *args, test_type=..., error_on_other_type=..., **kwargs): # -> Any | Mapping[Any, Any]:
    """
    Recursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.

    Args:
        func (`callable`):
            The function to recursively apply.
        data (nested list/tuple/dictionary of `main_type`):
            The data on which to apply `func`
        *args:
            Positional arguments that will be passed to `func` when applied on the unpacked data.
        main_type (`type`, *optional*, defaults to `torch.Tensor`):
            The base type of the objects to which apply `func`.
        error_on_other_type (`bool`, *optional*, defaults to `False`):
            Whether to return an error or not if after unpacking `data`, we get on an object that is not of type
            `main_type`. If `False`, the function will leave objects of types different than `main_type` unchanged.
        **kwargs (additional keyword arguments, *optional*):
            Keyword arguments that will be passed to `func` when applied on the unpacked data.

    Returns:
        The same data structure as `data` with `func` applied to every object of type `main_type`.
    """
    ...

def send_to_device(tensor, device, non_blocking=..., skip_keys=...): # -> Any | Mapping[Any, Any]:
    """
    Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device.

    Args:
        tensor (nested list/tuple/dictionary of `torch.Tensor`):
            The data to send to a given device.
        device (`torch.device`):
            The device to send the data to.

    Returns:
        The same data structure as `tensor` with all tensors sent to the proper device.
    """
    ...

def get_data_structure(data): # -> Any | Mapping[Any, Any]:
    """
    Recursively gathers the information needed to rebuild a nested list/tuple/dictionary of tensors.

    Args:
        data (nested list/tuple/dictionary of `torch.Tensor`):
            The data to send to analyze.

    Returns:
        The same data structure as `data` with [`~utils.TensorInformation`] instead of tensors.
    """
    ...

def get_shape(data): # -> Any | Mapping[Any, Any]:
    """
    Recursively gathers the shape of a nested list/tuple/dictionary of tensors as a list.

    Args:
        data (nested list/tuple/dictionary of `torch.Tensor`):
            The data to send to analyze.

    Returns:
        The same data structure as `data` with lists of tensor shapes instead of tensors.
    """
    ...

def initialize_tensors(data_structure): # -> Any | Mapping[Any, Any]:
    """
    Recursively initializes tensors from a nested list/tuple/dictionary of [`~utils.TensorInformation`].

    Returns:
        The same data structure as `data` with tensors instead of [`~utils.TensorInformation`].
    """
    ...

def find_batch_size(data): # -> int:
    """
    Recursively finds the batch size in a nested list/tuple/dictionary of lists of tensors.

    Args:
        data (nested list/tuple/dictionary of `torch.Tensor`): The data from which to find the batch size.

    Returns:
        `int`: The batch size.
    """
    ...

def ignorant_find_batch_size(data): # -> int | None:
    """
    Same as [`utils.operations.find_batch_size`] except will ignore if `ValueError` and `TypeErrors` are raised

    Args:
        data (nested list/tuple/dictionary of `torch.Tensor`): The data from which to find the batch size.

    Returns:
        `int`: The batch size.
    """
    ...

def listify(data): # -> Any | Mapping[Any, Any]:
    """
    Recursively finds tensors in a nested list/tuple/dictionary and converts them to a list of numbers.

    Args:
        data (nested list/tuple/dictionary of `torch.Tensor`): The data from which to convert to regular numbers.

    Returns:
        The same data structure as `data` with lists of numbers instead of `torch.Tensor`.
    """
    ...

class DistributedOperationException(Exception):
    """
    An exception class for distributed operations. Raised if the operation cannot be performed due to the shape of the
    tensors.
    """
    ...


def verify_operation(function): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    """
    Verifies that `tensor` is the same shape across all processes. Only ran if `PartialState().debug` is `True`.
    """
    ...

def chained_operation(function): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    """
    Checks that `verify_operation` failed and if so reports a more helpful error chaining the existing
    `DistributedOperationException`.
    """
    ...

@verify_operation
def gather(tensor): # -> Any | Mapping[Any, Any]:
    """
    Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices.

    Args:
        tensor (nested list/tuple/dictionary of `torch.Tensor`):
            The data to gather.

    Returns:
        The same data structure as `tensor` with all tensors sent to the proper device.
    """
    ...

def gather_object(object: Any): # -> list[Any] | Any:
    """
    Recursively gather object in a nested list/tuple/dictionary of objects from all devices.

    Args:
        object (nested list/tuple/dictionary of picklable object):
            The data to gather.

    Returns:
        The same data structure as `object` with all the objects sent to every device.
    """
    ...

TENSOR_TYPE_TO_INT = ...
TENSOR_INT_TO_DTYPE = ...
def gather_tensor_shape(tensor): # -> tuple[Any, int]:
    """
    Grabs the shape of `tensor` only available on one process and returns a tensor of its shape
    """
    ...

def copy_tensor_to_devices(tensor=...) -> torch.Tensor:
    """
    Copies a tensor that only exists on a single device and broadcasts it to other devices. Differs from `broadcast` as
    each worker doesn't need to know its shape when used (and tensor can be `None`)

    Args:
        tensor (`torch.tensor`):
            The tensor that should be sent to all devices. Must only have it be defined on a single device, the rest
            should be `None`.
    """
    ...

@verify_operation
def broadcast(tensor, from_process: int = ...): # -> Any | Mapping[Any, Any]:
    """
    Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices.

    Args:
        tensor (nested list/tuple/dictionary of `torch.Tensor`):
            The data to gather.
        from_process (`int`, *optional*, defaults to 0):
            The process from which to send the data

    Returns:
        The same data structure as `tensor` with all tensors broadcasted to the proper device.
    """
    ...

def broadcast_object_list(object_list, from_process: int = ...):
    """
    Broadcast a list of picklable objects form one process to the others.

    Args:
        object_list (list of picklable objects):
            The list of objects to broadcast. This list will be modified inplace.
        from_process (`int`, *optional*, defaults to 0):
            The process from which to send the data.

    Returns:
        The same list containing the objects from process 0.
    """
    ...

def slice_tensors(data, tensor_slice, process_index=..., num_processes=...): # -> Any | Mapping[Any, Any]:
    """
    Recursively takes a slice in a nested list/tuple/dictionary of tensors.

    Args:
        data (nested list/tuple/dictionary of `torch.Tensor`):
            The data to slice.
        tensor_slice (`slice`):
            The slice to take.

    Returns:
        The same data structure as `data` with all the tensors slices.
    """
    ...

def concatenate(data, dim=...): # -> Any | Tensor:
    """
    Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape.

    Args:
        data (nested list/tuple/dictionary of lists of tensors `torch.Tensor`):
            The data to concatenate.
        dim (`int`, *optional*, defaults to 0):
            The dimension on which to concatenate.

    Returns:
        The same data structure as `data` with all the tensors concatenated.
    """
    ...

class CannotPadNestedTensorWarning(UserWarning):
    ...


@chained_operation
def pad_across_processes(tensor, dim=..., pad_index=..., pad_first=...): # -> Any | Mapping[Any, Any]:
    """
    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
    can safely be gathered.

    Args:
        tensor (nested list/tuple/dictionary of `torch.Tensor`):
            The data to gather.
        dim (`int`, *optional*, defaults to 0):
            The dimension on which to pad.
        pad_index (`int`, *optional*, defaults to 0):
            The value with which to pad.
        pad_first (`bool`, *optional*, defaults to `False`):
            Whether to pad at the beginning or the end.
    """
    ...

def pad_input_tensors(tensor, batch_size, num_processes, dim=...): # -> Any | Mapping[Any, Any]:
    """
    Takes a `tensor` of arbitrary size and pads it so that it can work given `num_processes` needed dimensions.

    New tensors are just the last input repeated.

    E.g.:
      Tensor: ([3,4,4]) Num processes: 4 Expected result shape: ([4,4,4])

    """
    ...

@verify_operation
def reduce(tensor, reduction=..., scale=...): # -> Any | Mapping[Any, Any]:
    """
    Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
    mean of a given operation.

    Args:
        tensor (nested list/tuple/dictionary of `torch.Tensor`):
            The data to reduce.
        reduction (`str`, *optional*, defaults to `"mean"`):
            A reduction method. Can be of "mean", "sum", or "none"
        scale (`float`, *optional*):
            A default scaling value to be applied after the reduce, only valid on XLA.

    Returns:
        The same data structure as `data` with all the tensors reduced.
    """
    ...

def convert_to_fp32(tensor): # -> Any | Mapping[Any, Any]:
    """
    Recursively converts the elements nested list/tuple/dictionary of tensors in FP16/BF16 precision to FP32.

    Args:
        tensor (nested list/tuple/dictionary of `torch.Tensor`):
            The data to convert from FP16/BF16 to FP32.

    Returns:
        The same data structure as `tensor` with all tensors that were in FP16/BF16 precision converted to FP32.
    """
    ...

class ConvertOutputsToFp32:
    """
    Decorator to apply to a function outputting tensors (like a model forward pass) that ensures the outputs in FP16
    precision will be convert back to FP32.

    Args:
        model_forward (`Callable`):
            The function which outputs we want to treat.

    Returns:
        The same function as `model_forward` but with converted outputs.
    """
    def __init__(self, model_forward) -> None:
        ...
    
    def __call__(self, *args, **kwargs): # -> Any | Mapping[Any, Any]:
        ...
    
    def __getstate__(self):
        ...
    


def convert_outputs_to_fp32(model_forward): # -> Callable[..., Any | Mapping[Any, Any]]:
    ...

def find_device(data): # -> device | None:
    """
    Finds the device on which a nested dict/list/tuple of tensors lies (assuming they are all on the same device).

    Args:
        (nested list/tuple/dictionary of `torch.Tensor`): The data we want to know the device of.
    """
    ...

@contextmanager
def GatheredParameters(params, modifier_rank=..., fwd_module=..., enabled=...): # -> Generator[None, Any, None]:
    """
    Wrapper around `deepspeed.runtime.zero.GatheredParameters`, but if Zero-3 is not enabled, will be a no-op context
    manager.
    """
    ...

