"""
This type stub file was generated by pyright.
"""

import unittest
from contextlib import contextmanager
from pathlib import Path
from typing import Optional, Union
from unittest import mock

def get_backend(): # -> tuple[Literal['xla'], int, Callable[..., int]] | tuple[Literal['cuda'], int, Callable[..., int]] | tuple[Literal['mps'], Literal[1], Callable[[], int]] | tuple[Literal['mps'], Literal[1], Callable[[], Literal[0]]] | tuple[Literal['mlu'], Any, Any] | tuple[Literal['sdaa'], Any, Any] | tuple[Literal['musa'], Any, Any] | tuple[Literal['npu'], Any, Any] | tuple[Literal['xpu'], int, Callable[..., int]] | tuple[Literal['hpu'], Any, Any] | tuple[Literal['cpu'], Literal[1], Callable[[], Literal[0]]]:
    ...

def get_launch_command(**kwargs) -> list:
    """
    Wraps around `kwargs` to help simplify launching from `subprocess`.

    Example:
    ```python
    # returns ['accelerate', 'launch', '--num_processes=2', '--device_count=2']
    get_launch_command(num_processes=2, device_count=2)
    ```
    """
    ...

DEFAULT_LAUNCH_COMMAND = ...
def parse_flag_from_env(key, default=...): # -> int | bool:
    ...

_run_slow_tests = ...
def skip(test_case):
    "Decorator that skips a test unconditionally"
    ...

def slow(test_case):
    """
    Decorator marking a test as slow. Slow tests are skipped by default. Set the RUN_SLOW environment variable to a
    truthy value to run them.
    """
    ...

def require_cpu(test_case):
    """
    Decorator marking a test that must be only ran on the CPU. These tests are skipped when a GPU is available.
    """
    ...

def require_non_cpu(test_case):
    """
    Decorator marking a test that requires a hardware accelerator backend. These tests are skipped when there are no
    hardware accelerator available.
    """
    ...

def require_cuda(test_case):
    """
    Decorator marking a test that requires CUDA. These tests are skipped when there are no GPU available or when
    TorchXLA is available.
    """
    ...

def require_cuda_or_hpu(test_case):
    """
    Decorator marking a test that requires CUDA or HPU. These tests are skipped when there are no GPU available or when
    TorchXLA is available.
    """
    ...

def require_xpu(test_case):
    """
    Decorator marking a test that requires XPU. These tests are skipped when there are no XPU available.
    """
    ...

def require_cuda_or_xpu(test_case):
    """
    Decorator marking a test that requires CUDA or XPU. These tests are skipped when there are no GPU available or when
    TorchXLA is available.
    """
    ...

def require_non_xpu(test_case):
    """
    Decorator marking a test that should be skipped for XPU.
    """
    ...

def require_non_hpu(test_case):
    """
    Decorator marking a test that should be skipped for HPU.
    """
    ...

def require_fp16(test_case):
    """
    Decorator marking a test that requires FP16. These tests are skipped when FP16 is not supported.
    """
    ...

def require_fp8(test_case):
    """
    Decorator marking a test that requires FP8. These tests are skipped when FP8 is not supported.
    """
    ...

def require_fsdp2(test_case):
    ...

def require_mlu(test_case):
    """
    Decorator marking a test that requires MLU. These tests are skipped when there are no MLU available.
    """
    ...

def require_sdaa(test_case):
    """
    Decorator marking a test that requires SDAA. These tests are skipped when there are no SDAA available.
    """
    ...

def require_musa(test_case):
    """
    Decorator marking a test that requires MUSA. These tests are skipped when there are no MUSA available.
    """
    ...

def require_npu(test_case):
    """
    Decorator marking a test that requires NPU. These tests are skipped when there are no NPU available.
    """
    ...

def require_mps(test_case):
    """
    Decorator marking a test that requires MPS backend. These tests are skipped when torch doesn't support `mps`
    backend.
    """
    ...

def require_huggingface_suite(test_case):
    """
    Decorator marking a test that requires transformers and datasets. These tests are skipped when they are not.
    """
    ...

def require_transformers(test_case):
    """
    Decorator marking a test that requires transformers. These tests are skipped when they are not.
    """
    ...

def require_timm(test_case):
    """
    Decorator marking a test that requires timm. These tests are skipped when they are not.
    """
    ...

def require_torchvision(test_case):
    """
    Decorator marking a test that requires torchvision. These tests are skipped when they are not.
    """
    ...

def require_triton(test_case):
    """
    Decorator marking a test that requires triton. These tests are skipped when they are not.
    """
    ...

def require_schedulefree(test_case):
    """
    Decorator marking a test that requires schedulefree. These tests are skipped when they are not.
    """
    ...

def require_bnb(test_case):
    """
    Decorator marking a test that requires bitsandbytes. These tests are skipped when they are not.
    """
    ...

def require_tpu(test_case):
    """
    Decorator marking a test that requires TPUs. These tests are skipped when there are no TPUs available.
    """
    ...

def require_non_torch_xla(test_case):
    """
    Decorator marking a test as requiring an environment without TorchXLA. These tests are skipped when TorchXLA is
    available.
    """
    ...

def require_single_device(test_case):
    """
    Decorator marking a test that requires a single device. These tests are skipped when there is no hardware
    accelerator available or number of devices is more than one.
    """
    ...

def require_single_gpu(test_case):
    """
    Decorator marking a test that requires CUDA on a single GPU. These tests are skipped when there are no GPU
    available or number of GPUs is more than one.
    """
    ...

def require_single_xpu(test_case):
    """
    Decorator marking a test that requires CUDA on a single XPU. These tests are skipped when there are no XPU
    available or number of xPUs is more than one.
    """
    ...

def require_multi_device(test_case):
    """
    Decorator marking a test that requires a multi-device setup. These tests are skipped on a machine without multiple
    devices.
    """
    ...

def require_multi_gpu(test_case):
    """
    Decorator marking a test that requires a multi-GPU setup. These tests are skipped on a machine without multiple
    GPUs.
    """
    ...

def require_multi_xpu(test_case):
    """
    Decorator marking a test that requires a multi-XPU setup. These tests are skipped on a machine without multiple
    XPUs.
    """
    ...

def require_multi_gpu_or_xpu(test_case):
    """
    Decorator marking a test that requires a multi-GPU setup. These tests are skipped on a machine without multiple
    GPUs or XPUs.
    """
    ...

def require_deepspeed(test_case):
    """
    Decorator marking a test that requires DeepSpeed installed. These tests are skipped when DeepSpeed isn't installed
    """
    ...

def require_tp(test_case):
    """
    Decorator marking a test that requires TP installed. These tests are skipped when TP isn't installed
    """
    ...

def require_torch_min_version(test_case=..., version=...): # -> partial[Any]:
    """
    Decorator marking that a test requires a particular torch version to be tested. These tests are skipped when an
    installed torch version is less than the required one.
    """
    ...

def require_tensorboard(test_case):
    """
    Decorator marking a test that requires tensorboard installed. These tests are skipped when tensorboard isn't
    installed
    """
    ...

def require_wandb(test_case):
    """
    Decorator marking a test that requires wandb installed. These tests are skipped when wandb isn't installed
    """
    ...

def require_trackio(test_case):
    """
    Decorator marking a test that requires trackio installed. These tests are skipped when trackio isn't installed
    """
    ...

def require_comet_ml(test_case):
    """
    Decorator marking a test that requires comet_ml installed. These tests are skipped when comet_ml isn't installed
    """
    ...

def require_aim(test_case):
    """
    Decorator marking a test that requires aim installed. These tests are skipped when aim isn't installed
    """
    ...

def require_clearml(test_case):
    """
    Decorator marking a test that requires clearml installed. These tests are skipped when clearml isn't installed
    """
    ...

def require_dvclive(test_case):
    """
    Decorator marking a test that requires dvclive installed. These tests are skipped when dvclive isn't installed
    """
    ...

def require_swanlab(test_case):
    """
    Decorator marking a test that requires swanlab installed. These tests are skipped when swanlab isn't installed
    """
    ...

def require_pandas(test_case):
    """
    Decorator marking a test that requires pandas installed. These tests are skipped when pandas isn't installed
    """
    ...

def require_mlflow(test_case):
    """
    Decorator marking a test that requires mlflow installed. These tests are skipped when mlflow isn't installed
    """
    ...

def require_pippy(test_case):
    """
    Decorator marking a test that requires pippy installed. These tests are skipped when pippy isn't installed It is
    also checked if the test is running on a Gaudi1 device which doesn't support pippy.
    """
    ...

def require_import_timer(test_case):
    """
    Decorator marking a test that requires tuna interpreter installed. These tests are skipped when tuna isn't
    installed
    """
    ...

def require_transformer_engine(test_case):
    """
    Decorator marking a test that requires transformers engine installed. These tests are skipped when transformers
    engine isn't installed
    """
    ...

def require_transformer_engine_mxfp8(test_case):
    """
    Decorator marking a test that requires transformers engine MXFP8 block scaling available. These tests are skipped
    when transformers engine MXFP8 block scaling isn't available
    """
    ...

def require_torchao(test_case):
    """
    Decorator marking a test that requires torchao installed. These tests are skipped when torchao isn't installed
    """
    ...

def require_matplotlib(test_case):
    """
    Decorator marking a test that requires matplotlib installed. These tests are skipped when matplotlib isn't
    installed
    """
    ...

_atleast_one_tracker_available = ...
def require_trackers(test_case):
    """
    Decorator marking that a test requires at least one tracking library installed. These tests are skipped when none
    are installed
    """
    ...

def require_torchdata_stateful_dataloader(test_case):
    """
    Decorator marking a test that requires torchdata.stateful_dataloader.

    These tests are skipped when torchdata with stateful_dataloader module isn't installed.

    """
    ...

def run_first(test_case):
    """
    Decorator marking a test with order(1). When pytest-order plugin is installed, tests marked with this decorator are
    guaranteed to run first.

    This is especially useful in some test settings like on a Gaudi instance where a Gaudi device can only be used by a
    single process at a time. So we make sure all tests that run in a subprocess are launched first, to avoid device
    allocation conflicts.

    If pytest is not installed, test will be returned as is.
    """
    ...

class TempDirTestCase(unittest.TestCase):
    """
    A TestCase class that keeps a single `tempfile.TemporaryDirectory` open for the duration of the class, wipes its
    data at the start of a test, and then destroys it at the end of the TestCase.

    Useful for when a class or API requires a single constant folder throughout it's use, such as Weights and Biases

    The temporary directory location will be stored in `self.tmpdir`
    """
    clear_on_setup = ...
    @classmethod
    def setUpClass(cls): # -> None:
        "Creates a `tempfile.TemporaryDirectory` and stores it in `cls.tmpdir`"
        ...
    
    @classmethod
    def tearDownClass(cls): # -> None:
        "Remove `cls.tmpdir` after test suite has finished"
        ...
    
    def setUp(self): # -> None:
        "Destroy all contents in `self.tmpdir`, but not `self.tmpdir`"
        ...
    


class AccelerateTestCase(unittest.TestCase):
    """
    A TestCase class that will reset the accelerator state at the end of every test. Every test that checks or utilizes
    the `AcceleratorState` class should inherit from this to avoid silent failures due to state being shared between
    tests.
    """
    def tearDown(self): # -> None:
        ...
    


class MockingTestCase(unittest.TestCase):
    """
    A TestCase class designed to dynamically add various mockers that should be used in every test, mimicking the
    behavior of a class-wide mock when defining one normally will not do.

    Useful when a mock requires specific information available only initialized after `TestCase.setUpClass`, such as
    setting an environment variable with that information.

    The `add_mocks` function should be ran at the end of a `TestCase`'s `setUp` function, after a call to
    `super().setUp()` such as:
    ```python
    def setUp(self):
        super().setUp()
        mocks = mock.patch.dict(os.environ, {"SOME_ENV_VAR", "SOME_VALUE"})
        self.add_mocks(mocks)
    ```
    """
    def add_mocks(self, mocks: Union[mock.Mock, list[mock.Mock]]): # -> None:
        """
        Add custom mocks for tests that should be repeated on each test. Should be called during
        `MockingTestCase.setUp`, after `super().setUp()`.

        Args:
            mocks (`mock.Mock` or list of `mock.Mock`):
                Mocks that should be added to the `TestCase` after `TestCase.setUpClass` has been run
        """
        ...
    


def are_the_same_tensors(tensor): # -> bool:
    ...

class _RunOutput:
    def __init__(self, returncode, stdout, stderr) -> None:
        ...
    


def execute_subprocess_async(cmd: list, env=..., stdin=..., timeout=..., quiet=..., echo=...) -> _RunOutput:
    ...

def pytest_xdist_worker_id(): # -> int:
    """
    Returns an int value of worker's numerical id under `pytest-xdist`'s concurrent workers `pytest -n N` regime, or 0
    if `-n 1` or `pytest-xdist` isn't being used.
    """
    ...

def get_torch_dist_unique_port(): # -> int:
    """
    Returns a port number that can be fed to `torch.distributed.launch`'s `--master_port` argument.

    Under `pytest-xdist` it adds a delta number based on a worker id so that concurrent tests don't try to use the same
    port at once.
    """
    ...

class SubprocessCallException(Exception):
    ...


def run_command(command: list[str], return_stdout=..., env=...): # -> str | bytes | None:
    """
    Runs `command` with `subprocess.check_output` and will potentially return the `stdout`. Will also properly capture
    if an error occurred while running `command`
    """
    ...

def path_in_accelerate_package(*components: str) -> Path:
    """
    Get a path within the `accelerate` package's directory.

    Args:
        *components: Components of the path to join after the package directory.

    Returns:
        `Path`: The path to the requested file or directory.
    """
    ...

@contextmanager
def assert_exception(exception_class: Exception, msg: Optional[str] = ...) -> bool:
    """
    Context manager to assert that the right `Exception` class was raised.

    If `msg` is provided, will check that the message is contained in the raised exception.
    """
    ...

def capture_call_output(func, *args, **kwargs): # -> str:
    """
    Takes in a `func` with `args` and `kwargs` and returns the captured stdout as a string
    """
    ...

